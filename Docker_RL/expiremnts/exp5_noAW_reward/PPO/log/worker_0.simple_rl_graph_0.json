sess: 
<tensorflow.python.client.session.Session object at 0x7f32cbb07940>
level_managers: 
0: <rl_coach.level_manager.LevelManager object at 0x7f32cbaf8ac8>

top_level_manager: 
<rl_coach.level_manager.LevelManager object at 0x7f32cbaf8ac8>
environments: 
0: <rl_coach.environments.gym_environment.GymEnvironment object at 0x7f32d8e5c0b8>

heatup_steps: 
<rl_coach.core_types.EnvironmentSteps object at 0x7f32d8eb57f0>
evaluation_steps: 
<rl_coach.core_types.EnvironmentEpisodes object at 0x7f32d8eb56d8>
steps_between_evaluation_periods: 
<rl_coach.core_types.EnvironmentSteps object at 0x7f32d8eb5780>
improve_steps: 
<rl_coach.core_types.TrainingSteps object at 0x7f32d8eb5630>
visualization_parameters: 
"VisualizationParameters" {
    "add_rendered_image_to_env_response": false,
    "dump_csv": true,
    "dump_gifs": false,
    "dump_in_episode_signals": false,
    "dump_mp4": false,
    "dump_parameters_documentation": true,
    "dump_signals_to_csv_every_x_episodes": 5,
    "max_fps_for_human_control": 10,
    "native_rendering": false,
    "print_networks_summary": false,
    "render": false,
    "tensorboard": false,
    "video_dump_filters": {
        "0": {
            "run_phases": {
                "0": {
                    "_value_": "Testing",
                    "_name_": "TEST",
                    "__objclass__": "<enum 'RunPhase'>"
                }
            },
            "__class__": "SelectedPhaseOnlyDumpFilter"
        },
        "1": {
            "max_reward_achieved": -Infinity,
            "__class__": "MaxDumpFilter"
        }
    }
}

name: 
simple_rl_graph
task_parameters: 
"TaskParameters" {
    "apply_stop_condition": false,
    "checkpoint_restore_path": null,
    "checkpoint_save_dir": "./../Expirements/exp5_noAW_reward_ass/PPO/saved_model",
    "checkpoint_save_secs": 600,
    "evaluate_only": null,
    "experiment_path": "./../Expirements/exp5_noAW_reward_ass/PPO/log",
    "export_onnx_graph": false,
    "framework_type": {
        "_value_": "TensorFlow",
        "_name_": "tensorflow",
        "__objclass__": "<enum 'Frameworks'>"
    },
    "num_gpu": 1,
    "seed": null,
    "task_index": 0,
    "use_cpu": false
}

_phase: 
RunPhase.UNDEFINED
preset_validation_params: 
"PresetValidationParameters" {
    "max_episodes_to_achieve_reward": 400,
    "min_reward_threshold": 150,
    "num_workers": 1,
    "read_csv_tries": 200,
    "reward_test_level": null,
    "test": true,
    "test_using_a_trace_test": true,
    "trace_max_env_steps": 5000,
    "trace_test_levels": null
}

reset_required: 
False
graph_creation_time: 
1613653340.3856504
last_checkpoint_saving_time: 
1613653340.3849783
total_steps_counters: 
RunPhase.HEATUP: <rl_coach.core_types.TotalStepsCounter object at 0x7f32d8eb5dd8>
RunPhase.TRAIN: <rl_coach.core_types.TotalStepsCounter object at 0x7f32d8eb5cc0>
RunPhase.TEST: <rl_coach.core_types.TotalStepsCounter object at 0x7f32d8eb5ef0>

checkpoint_id: 
0
checkpoint_saver: 
<rl_coach.saver.SaverCollection object at 0x7f32cbb07710>
checkpoint_state_updater: 
None
graph_logger: 
<rl_coach.logger.Logger object at 0x7f32d8eb5e10>
data_store: 
None
is_batch_rl: 
False
time_metric: 
TimeTypes.EpisodeNumber
agent_params: 
"ClippedPPOAgentParameters" {
    "algorithm": {
        "act_for_full_episodes": true,
        "apply_gradients_every_x_episodes": 5,
        "beta_entropy": 0,
        "clip_likelihood_ratio_using_epsilon": 0.2,
        "clipping_decay_schedule": {
            "current_value": 1,
            "initial_value": 1,
            "__class__": "ConstantSchedule"
        },
        "discount": 0.99,
        "distributed_coach_synchronization_type": {
            "_value_": "sync",
            "_name_": "SYNC",
            "__objclass__": "<enum 'DistributedCoachSynchronizationType'>"
        },
        "estimate_state_value_using_gae": true,
        "gae_lambda": 0.95,
        "heatup_using_network_decisions": false,
        "in_action_space": null,
        "load_memory_from_file_path": null,
        "n_step": -1,
        "normalization_stats": null,
        "num_consecutive_playing_steps": {
            "_num_steps": 2048,
            "__class__": "EnvironmentSteps"
        },
        "num_consecutive_training_steps": 1,
        "num_episodes_in_experience_replay": 1000000,
        "num_steps_between_copying_online_weights_to_target": {
            "_num_steps": 2048,
            "__class__": "EnvironmentSteps"
        },
        "optimization_epochs": 10,
        "override_episode_rewards_with_the_last_transition_reward": false,
        "policy_gradient_rescaler": {
            "_value_": 8,
            "_name_": "GAE",
            "__objclass__": "<enum 'PolicyGradientRescaler'>"
        },
        "rate_for_copying_weights_to_target": 1.0,
        "share_statistics_between_workers": true,
        "store_transitions_only_when_episodes_are_terminated": false,
        "supports_parameter_noise": false,
        "update_pre_network_filters_state_on_inference": false,
        "update_pre_network_filters_state_on_train": true,
        "use_accumulated_reward_as_measurement": false,
        "use_kl_regularization": false,
        "__class__": "ClippedPPOAlgorithmParameters"
    },
    "current_episode": 0,
    "exploration": {
        "action_space": {
            "_high": "array([2.96706 , 2.0944  , 2.96706 , 2.0944  , 2.96706 , 2.0944  ,\n       3.05433 , 1.5708  , 1.5708  , 1.5708  , 0.349066, 1.5708  ,\n       1.5708  , 1.5708  , 0.349066, 1.5708  , 1.5708  , 1.5708  ,\n       0.349066, 1.0472  , 1.22173 , 0.698132, 1.5708  ], dtype=float32)",
            "_low": "array([-2.96706 , -2.0944  , -2.96706 , -2.0944  , -2.96706 , -2.0944  ,\n       -3.05433 ,  0.      ,  0.      ,  0.      , -0.349066,  0.      ,\n        0.      ,  0.      , -0.349066,  0.      ,  0.      ,  0.      ,\n       -0.349066, -1.0472  ,  0.      , -0.698132,  0.      ],\n      dtype=float32)",
            "_shape": "array([23])",
            "default_action": "array([0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n       0.      , 0.7854  , 0.7854  , 0.7854  , 0.      , 0.7854  ,\n       0.7854  , 0.7854  , 0.      , 0.7854  , 0.7854  , 0.7854  ,\n       0.      , 0.      , 0.610865, 0.      , 0.7854  ], dtype=float32)",
            "descriptions": {},
            "max_abs_range": "array([2.96706 , 2.0944  , 2.96706 , 2.0944  , 2.96706 , 2.0944  ,\n       3.05433 , 1.5708  , 1.5708  , 1.5708  , 0.349066, 1.5708  ,\n       1.5708  , 1.5708  , 0.349066, 1.5708  , 1.5708  , 1.5708  ,\n       0.349066, 1.0472  , 1.22173 , 0.698132, 1.5708  ], dtype=float32)",
            "num_dimensions": 1,
            "num_elements": 23,
            "__class__": "BoxActionSpace"
        },
        "evaluation_noise": 0.05,
        "noise_as_percentage_from_action_space": true,
        "noise_schedule": {
            "current_value": 0.1,
            "decay_delta": 0.0,
            "decay_steps": 50000,
            "final_value": 0.1,
            "initial_value": 0.1,
            "__class__": "LinearSchedule"
        },
        "__class__": "AdditiveNoiseParameters"
    },
    "full_name_id": "main_level/agent",
    "input_filter": {
        "_observation_filters": {},
        "_reward_filters": {},
        "i_am_a_reference_filter": false,
        "name": "input_filter",
        "__class__": "NoInputFilter"
    },
    "is_a_highest_level_agent": true,
    "is_a_lowest_level_agent": true,
    "is_batch_rl_training": false,
    "memory": {
        "load_memory_from_file_path": null,
        "max_size": [
            "<MemoryGranularity.Transitions: 0>",
            1000000
        ],
        "n_step": -1,
        "shared_memory": false,
        "train_to_eval_ratio": 1,
        "__class__": "EpisodicExperienceReplayParameters"
    },
    "name": "agent",
    "network_wrappers": {
        "main": {
            "adam_optimizer_beta1": 0.9,
            "adam_optimizer_beta2": 0.999,
            "async_training": false,
            "batch_size": 64,
            "clip_gradients": null,
            "create_target_network": true,
            "embedding_merger_type": {
                "_value_": 0,
                "_name_": "Concat",
                "__objclass__": "<enum 'EmbeddingMergerType'>"
            },
            "force_cpu": false,
            "framework": {
                "_value_": "TensorFlow",
                "_name_": "tensorflow",
                "__objclass__": "<enum 'Frameworks'>"
            },
            "gradients_clipping_method": {
                "_value_": 0,
                "_name_": "ClipByGlobalNorm",
                "__objclass__": "<enum 'GradientClippingMethod'>"
            },
            "heads_parameters": {
                "0": {
                    "activation_function": "relu",
                    "dense_layer": null,
                    "initializer": "normalized_columns",
                    "is_training": false,
                    "loss_weight": 1.0,
                    "name": "v_head_params",
                    "num_output_head_copies": 1,
                    "output_bias_initializer": null,
                    "parameterized_class_name": "VHead",
                    "rescale_gradient_from_head_by_factor": 1.0,
                    "__class__": "VHeadParameters"
                },
                "1": {
                    "activation_function": "tanh",
                    "dense_layer": null,
                    "is_training": false,
                    "loss_weight": 1.0,
                    "name": "ppo_head_params",
                    "num_output_head_copies": 1,
                    "parameterized_class_name": "PPOHead",
                    "rescale_gradient_from_head_by_factor": 1.0,
                    "__class__": "PPOHeadParameters"
                }
            },
            "input_embedders_parameters": {
                "observation": {
                    "activation_function": "tanh",
                    "batchnorm": false,
                    "dense_layer": null,
                    "dropout_rate": 0.0,
                    "input_clipping": null,
                    "input_offset": {
                        "image": 0.0,
                        "tensor": 0.0,
                        "vector": 0.0
                    },
                    "input_rescaling": {
                        "image": 255.0,
                        "tensor": 1.0,
                        "vector": 1.0
                    },
                    "is_training": false,
                    "name": "embedder",
                    "scheme": {
                        "0": {
                            "units": 64,
                            "__class__": "Dense"
                        },
                        "1": {
                            "units": 64,
                            "__class__": "Dense"
                        },
                        "2": {
                            "units": 64,
                            "__class__": "Dense"
                        }
                    },
                    "__class__": "InputEmbedderParameters"
                }
            },
            "l2_regularization": 0,
            "learning_rate": 0.0001,
            "learning_rate_decay_rate": 0,
            "learning_rate_decay_steps": 0,
            "middleware_parameters": {
                "activation_function": "tanh",
                "batchnorm": false,
                "dense_layer": null,
                "dropout_rate": 0.0,
                "is_training": false,
                "name": "middleware_fc_embedder",
                "num_streams": 1,
                "parameterized_class_name": "FCMiddleware",
                "scheme": {
                    "0": {
                        "units": 64,
                        "__class__": "Dense"
                    }
                },
                "__class__": "FCMiddlewareParameters"
            },
            "optimizer_epsilon": 1e-05,
            "optimizer_type": "Adam",
            "replace_mse_with_huber_loss": false,
            "rms_prop_optimizer_decay": 0.9,
            "scale_down_gradients_by_number_of_workers_for_sync_training": true,
            "sess": null,
            "shared_optimizer": true,
            "softmax_temperature": 1,
            "tensorflow_support": true,
            "use_separate_networks_per_head": true,
            "__class__": "ClippedPPONetworkParameters"
        }
    },
    "output_filter": {
        "_action_filters": {},
        "i_am_a_reference_filter": false,
        "name": "output_filter",
        "__class__": "NoOutputFilter"
    },
    "pre_network_filter": {
        "_observation_filters": {
            "observation": {
                "normalize_observation": {
                    "clip_max": 5.0,
                    "clip_min": -5.0,
                    "name": "normalize_observation",
                    "observation_space": null,
                    "running_observation_stats": {
                        "_count": 0.01,
                        "_mean": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])",
                        "_shape": "array([11])",
                        "_std": "array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])",
                        "_sum": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])",
                        "_sum_squares": "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01])",
                        "checkpoint_file_extension": "srs",
                        "clip_values": [
                            -5.0,
                            5.0
                        ],
                        "epsilon": 0.01,
                        "name": "normalize_observation",
                        "pubsub": null,
                        "__class__": "NumpySharedRunningStats"
                    },
                    "supports_batching": true,
                    "__class__": "ObservationNormalizationFilter"
                }
            }
        },
        "_reward_filters": {},
        "i_am_a_reference_filter": false,
        "name": "pre_network_filter",
        "__class__": "InputFilter"
    },
    "task_parameters": {
        "apply_stop_condition": false,
        "checkpoint_restore_path": null,
        "checkpoint_save_dir": "./../Expirements/exp5_noAW_reward_ass/PPO/saved_model",
        "checkpoint_save_secs": 600,
        "evaluate_only": null,
        "experiment_path": "./../Expirements/exp5_noAW_reward_ass/PPO/log",
        "export_onnx_graph": false,
        "framework_type": {
            "_value_": "TensorFlow",
            "_name_": "tensorflow",
            "__objclass__": "<enum 'Frameworks'>"
        },
        "num_gpu": 1,
        "seed": null,
        "task_index": 0,
        "use_cpu": false,
        "__class__": "TaskParameters"
    },
    "visualization": {
        "add_rendered_image_to_env_response": false,
        "dump_csv": true,
        "dump_gifs": false,
        "dump_in_episode_signals": false,
        "dump_mp4": false,
        "dump_parameters_documentation": true,
        "dump_signals_to_csv_every_x_episodes": 5,
        "max_fps_for_human_control": 10,
        "native_rendering": false,
        "print_networks_summary": false,
        "render": false,
        "tensorboard": false,
        "video_dump_filters": {
            "0": {
                "run_phases": {
                    "0": {
                        "_value_": "Testing",
                        "_name_": "TEST",
                        "__objclass__": "<enum 'RunPhase'>"
                    }
                },
                "__class__": "SelectedPhaseOnlyDumpFilter"
            },
            "1": {
                "max_reward_achieved": -Infinity,
                "__class__": "MaxDumpFilter"
            }
        },
        "__class__": "VisualizationParameters"
    }
}

env_params: 
"GymVectorEnvironment" {
    "additional_simulator_parameters": {
        "AW_mode": null,
        "AW_progress_path": "./../Expirements/exp5_noAW_reward_ass/PPO/AW_progress",
        "AW_setting": {
            "initial_r": {
                "0": 0.3,
                "1": 0.4
            },
            "obs_mode": "palm"
        },
        "action_mode": "jointControl",
        "env_setting_path": "./../Expirements/exp5_noAW_reward_ass/PPO/gym_env_setting",
        "expirement_path": "/home/mamad/hand_RL_ws/src/iiwa_pybullet_integration/Training/kuka_PPO_Algorithem7/ppo_presets/./../Expirements/exp5_noAW_reward_ass/PPO/",
        "obs_mode": "palm_world",
        "record_training": false,
        "renders": false,
        "reward_function_choice": 8,
        "reward_obs_mode": "palm",
        "training": true
    },
    "custom_reward_threshold": 200,
    "default_input_filter": {
        "_observation_filters": {},
        "_reward_filters": {},
        "i_am_a_reference_filter": false,
        "name": "no_input_filter",
        "__class__": "NoInputFilter"
    },
    "default_output_filter": {
        "_action_filters": {},
        "i_am_a_reference_filter": false,
        "name": null,
        "__class__": "NoOutputFilter"
    },
    "experiment_path": "./../Expirements/exp5_noAW_reward_ass/PPO/log",
    "frame_skip": 1,
    "human_control": false,
    "level": "kuka_handlit.envs.kuka_handlitGymEnv:Kuka_HandlitGymEnv",
    "max_over_num_frames": 1,
    "observation_space_type": null,
    "random_initialization_steps": 0,
    "seed": null,
    "target_success_rate": 1.0
}

